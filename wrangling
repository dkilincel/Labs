import nbformat

# Load the notebook file
file_path = '/mnt/data/M2DataWrangling-lab-v2-v1.ipynb'
with open(file_path, 'r', encoding='utf-8') as file:
    notebook = nbformat.read(file, as_version=4)

# Display contents to identify the main data wrangling steps
notebook.cells[:10]  # Displaying the first 10 cells to understand context and main objectives
# Data Wrangling Lab - Python Implementation

# Importing necessary libraries
import pandas as pd

# Load dataset (Replace 'your_data.csv' with your actual data path)
df = pd.read_csv('your_data.csv')

# Check for missing values
print(df.isnull().sum())

# Handle missing values - Example: Filling numeric columns with mean and categorical with mode
for column in df.columns:
    if df[column].dtype in ['int64', 'float64']:
        df[column].fillna(df[column].mean(), inplace=True)
    else:
        df[column].fillna(df[column].mode()[0], inplace=True)

# Remove duplicate rows
df.drop_duplicates(inplace=True)

# Correct inconsistencies - Example (Replace actual conditions as needed)
# df['column_name'] = df['column_name'].replace({'incorrect_entry': 'corrected_entry'})

# Encode categorical variables (Example: One-hot encoding)
df_encoded = pd.get_dummies(df, drop_first=True)

# Normalize/Scale features (Example: Min-Max scaling)
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df_encoded[df_encoded.columns] = scaler.fit_transform(df_encoded[df_encoded.columns])

# Final dataset
print(df_encoded.head())

# Save cleaned dataset
df_encoded.to_csv('cleaned_data.csv', index=False)
